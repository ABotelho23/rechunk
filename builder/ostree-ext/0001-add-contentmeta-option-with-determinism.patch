From f300504073a64ab3f62054ec3f09bd7ba6a0e805 Mon Sep 17 00:00:00 2001
From: antheas <git@antheas.dev>
Date: Fri, 28 Jun 2024 17:12:33 +0200
Subject: [PATCH 1/3] add contentmeta option with determinism

---
 lib/src/chunking.rs | 20 ++++++++-------
 lib/src/cli.rs      | 62 +++++++++++++++++++++++++++++++++++++++++++++
 2 files changed, 73 insertions(+), 9 deletions(-)

diff --git a/lib/src/chunking.rs b/lib/src/chunking.rs
index 4b047e7..17c470b 100644
--- a/lib/src/chunking.rs
+++ b/lib/src/chunking.rs
@@ -3,7 +3,7 @@
 // SPDX-License-Identifier: Apache-2.0 OR MIT
 
 use std::borrow::{Borrow, Cow};
-use std::collections::{BTreeMap, BTreeSet, HashMap, HashSet};
+use std::collections::{BTreeMap, BTreeSet};
 use std::fmt::Write;
 use std::hash::{Hash, Hasher};
 use std::num::NonZeroU32;
@@ -53,9 +53,9 @@ pub(crate) struct Chunk {
 pub struct ObjectSourceMetaSized {
     /// The original metadata
     #[serde(flatten)]
-    meta: ObjectSourceMeta,
+    pub meta: ObjectSourceMeta,
     /// Total size of associated objects
-    size: u64,
+    pub size: u64,
 }
 
 impl Hash for ObjectSourceMetaSized {
@@ -89,7 +89,7 @@ impl ObjectMetaSized {
         let map = meta.map;
         let mut set = meta.set;
         // Maps content id -> total size of associated objects
-        let mut sizes = HashMap::<&str, u64>::new();
+        let mut sizes = BTreeMap::<&str, u64>::new();
         // Populate two mappings above, iterating over the object -> contentid mapping
         for (checksum, contentid) in map.iter() {
             let finfo = repo.query_file(checksum, cancellable)?.0;
@@ -308,7 +308,7 @@ impl Chunking {
         }
 
         // Reverses `contentmeta.map` i.e. contentid -> Vec<checksum>
-        let mut rmap = HashMap::<ContentID, Vec<&String>>::new();
+        let mut rmap = BTreeMap::<ContentID, Vec<&String>>::new();
         for (checksum, contentid) in meta.map.iter() {
             rmap.entry(Rc::clone(contentid)).or_default().push(checksum);
         }
@@ -577,12 +577,12 @@ fn basic_packing_with_prior_build<'a>(
     let mut curr_build = curr_build?;
 
     // View the packages as unordered sets for lookups and differencing
-    let prev_pkgs_set: HashSet<String> = curr_build
+    let prev_pkgs_set: BTreeSet<String> = curr_build
         .iter()
         .flat_map(|v| v.iter().cloned())
         .filter(|name| !name.is_empty())
         .collect();
-    let curr_pkgs_set: HashSet<String> = components
+    let curr_pkgs_set: BTreeSet<String> = components
         .iter()
         .map(|pkg| pkg.meta.name.to_string())
         .collect();
@@ -597,13 +597,13 @@ fn basic_packing_with_prior_build<'a>(
     }
 
     // Handle removed packages
-    let removed: HashSet<&String> = prev_pkgs_set.difference(&curr_pkgs_set).collect();
+    let removed: BTreeSet<&String> = prev_pkgs_set.difference(&curr_pkgs_set).collect();
     for bin in curr_build.iter_mut() {
         bin.retain(|pkg| !removed.contains(pkg));
     }
 
     // Handle updated packages
-    let mut name_to_component: HashMap<String, &ObjectSourceMetaSized> = HashMap::new();
+    let mut name_to_component: BTreeMap<String, &ObjectSourceMetaSized> = BTreeMap::new();
     for component in components.iter() {
         name_to_component
             .entry(component.meta.name.to_string())
@@ -821,6 +821,8 @@ mod test {
     }
 
     fn create_manifest(prev_expected_structure: Vec<Vec<&str>>) -> oci_spec::image::ImageManifest {
+        use std::collections::HashMap;
+
         let mut p = prev_expected_structure
             .iter()
             .map(|b| {
diff --git a/lib/src/cli.rs b/lib/src/cli.rs
index c9f91cb..9b22b14 100644
--- a/lib/src/cli.rs
+++ b/lib/src/cli.rs
@@ -19,16 +19,20 @@ use std::collections::BTreeMap;
 use std::ffi::OsString;
 use std::fs::File;
 use std::io::{BufReader, BufWriter, Write};
+use std::num::NonZeroU32;
 use std::path::PathBuf;
 use std::process::Command;
 use tokio::sync::mpsc::Receiver;
 
+use crate::chunking::{ObjectMetaSized, ObjectSourceMetaSized};
 use crate::commit::container_commit;
 use crate::container::store::{ExportToOCIOpts, ImportProgress, LayerProgress, PreparedImport};
 use crate::container::{self as ostree_container, ManifestDiff};
 use crate::container::{Config, ImageReference, OstreeImageReference};
+use crate::objectsource::ObjectSourceMeta;
 use crate::sysroot::SysrootLock;
 use ostree_container::store::{ImageImporter, PrepareResult};
+use serde::{Deserialize, Serialize};
 
 /// Parse an [`OstreeImageReference`] from a CLI arguemnt.
 pub fn parse_imgref(s: &str) -> Result<OstreeImageReference> {
@@ -165,6 +169,10 @@ pub(crate) enum ContainerOpts {
         /// Compress at the fastest level (e.g. gzip level 1)
         #[clap(long)]
         compression_fast: bool,
+
+        /// Path to a JSON-formatted content meta object.
+        #[clap(long)]
+        contentmeta: Option<Utf8PathBuf>,
     },
 
     /// Perform build-time checking and canonicalization.
@@ -699,6 +707,15 @@ async fn container_import(
     Ok(())
 }
 
+/// Grouping of metadata about an object.
+#[derive(Debug, Default, Serialize, Deserialize)]
+pub struct RawMeta {
+    /// ContentId to layer annotation
+    pub layers: BTreeMap<String, String>,
+    /// OSTree hash to layer ContentId
+    pub mapping: BTreeMap<String, String>,
+}
+
 /// Export a container image with an encapsulated ostree commit.
 #[allow(clippy::too_many_arguments)]
 async fn container_export(
@@ -712,6 +729,7 @@ async fn container_export(
     container_config: Option<Utf8PathBuf>,
     cmd: Option<Vec<String>>,
     compression_fast: bool,
+    contentmeta: Option<Utf8PathBuf>,
 ) -> Result<()> {
     let config = Config {
         labels: Some(labels),
@@ -722,12 +740,54 @@ async fn container_export(
     } else {
         None
     };
+    let contentmeta = if let Some(contentmeta) = contentmeta {
+        let raw: Option<RawMeta> =
+            serde_json::from_reader(File::open(contentmeta).map(BufReader::new)?)?;
+        if let Some(raw) = raw {
+            Some(ObjectMetaSized {
+                map: raw
+                    .mapping
+                    .into_iter()
+                    .map(|(k, v)| (k.into(), v.into()))
+                    .collect(),
+                sizes: raw
+                    .layers
+                    .into_iter()
+                    .map(|(k, v)| ObjectSourceMetaSized {
+                        meta: ObjectSourceMeta {
+                            identifier: k.clone().into(),
+                            name: v.into(),
+                            srcid: k.clone().into(),
+                            change_frequency: if k == "unpackaged" { std::u32::MAX } else { 1 },
+                            change_time_offset: 1,
+                        },
+                        size: 1,
+                    })
+                    .collect(),
+            })
+        } else {
+            anyhow::bail!("Content metadata must be a JSON object")
+        }
+    } else {
+        None
+    };
+
+    // Use enough layers so that each package ends in its own layer
+    // while respecting the layer ordering.
+    let max_layers = if let Some(contentmeta) = &contentmeta {
+        NonZeroU32::new(contentmeta.sizes.len().try_into().unwrap())
+    } else {
+        None
+    };
+
     let opts = crate::container::ExportOpts {
         copy_meta_keys,
         copy_meta_opt_keys,
         container_config,
         authfile,
         skip_compression: compression_fast, // TODO rename this in the struct at the next semver break
+        contentmeta: contentmeta.as_ref(),
+        max_layers,
         ..Default::default()
     };
     let pushed = crate::container::encapsulate(repo, rev, &config, Some(opts), imgref).await?;
@@ -958,6 +1018,7 @@ async fn run_from_opt(opt: Opt) -> Result<()> {
                 config,
                 cmd,
                 compression_fast,
+                contentmeta,
             } => {
                 let labels: Result<BTreeMap<_, _>> = labels
                     .into_iter()
@@ -980,6 +1041,7 @@ async fn run_from_opt(opt: Opt) -> Result<()> {
                     config,
                     cmd,
                     compression_fast,
+                    contentmeta,
                 )
                 .await
             }
-- 
2.45.2

